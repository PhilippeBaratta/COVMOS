[CATALOGUE_SETTINGS]
#project_name (str) is the name of the project under which the differents outputs will be saved. If you leave it empty, a repertory will be named following the relevant parameter set in this file
#total_number_of_cat (int) is the total number of catalogues that you want to simulate. It can be modified at any time
#rho_0 (float) is the expected density of particles per unit volume, in (Mpc/h)^{-3}
#assign_sheme (str) refers to the way particles are distributed in grid cells. Two options are available : 'tophat' (incompatible with velocity = True) or 'trilinear'. The 'trilinear' option ensure field continuity and more reliable output spectra, but is more cpu-consuming
#fixed_Rdm_seed (bin) allows to fix to deterministic values the stochastic Gaussian density field. If you don't know, set it to False
#L (float) is the cubical box size in Mpc/h
#N_sample (int) is the regularily spaced grid parameter, must be a power of 2 (like 256, 512, 1024, etc) for the FFTs to be computationnaly efficients
#redshift (float) is the redshift of the snapshots that will be simulated
#Omega_m (float) is the total fraction of matter density today
#aliasing_order (int,str) is related to the level of truncation of the aliasing sum (see eq.17 in arXiv/1906.09042) of the target density Pk, 0 means not aliased (not recommended), 2 is a good level (Default value). Note that if a .npy file is given in Pk_dd_file (see below), this variable is not read.

project_name        = 
total_number_of_cat = 100
rho_0               = 0.2
assign_scheme       = trilinear
fixed_Rdm_seed      = False
L                   = 1000.
N_sample            = 512 
redshift            = 0.
Omega_m             = 0.32
aliasing_order      = Default

[TARGET_STATISTICS]
#density field
#Pk_dd_file (str) is the path to the ascii file storing two columns: the wavemodes in h/Mpc and density power spectrum in [Mpc/h]^3 and in Fourier normalisation delta_k = (2pi)^-3 \int d^3x delta(x) e^(-ik.x) . If you want classy to compute it, leave this variable empty and return non-zero values for the classy parameters below. If you want NBodyKit to estimate the Pk on your own data, you can use compute_shell_average_monopole.py. You can also provide a 3D target power spectrum (in the same normalisation), that must be aliased and with the extension .npy, the code compute_3D_aliased_Pk.py helps the user to estimate it. This option is better since aliasing is already effective thanks to FFT
#PDF_d_file (str) is the path to the ascii file storing two columns: delta and the normalised PDF for the density field (make sure to provide it with high precision in delta). If you want COVMOS to estimate it from data, you can use the code compute_delta_PDF.py. If you want to produce Gaussian mocks with variance 0.01, type 'gaussian'
#filtering_parameter (int,float,str) represents the filtering i1 to apply on the input power spectrum in order for it to be compatible with the PDF (at the variance level). Default follows the empirical function filtering_i1_i2(redshift)

Pk_dd_file          = 
PDF_d_file          = /datadec/cppm/baratta/512_PCS
filtering_parameter = Default

#classy dictionnary parameters
#classy_dict (dict): these parameters are read if Pk_dd_file is empty or if Pk_tt_file is empty (while velocity = True). It will be used to compute the matter power spectrum or Pk_cb (if massive neutrinos are provided)

classy_dict = {'h': 0.67, 'Omega_b': 0.05, 'Omega_cdm':0.27, 'n_s':0.96, 'A_s':2.1265e-9, 'non linear':'halofit', 'output' : 'mPk'}

#velocity field
#Pk_tt_file (str) is the path to the ascii file storing two columns: k in h/Mpc and Pk_theta_theta in [Mpc/h]^3. If you want classy (combined to arxiv.org/abs/1906.07683) to compute it, leave this variable empty and return non-zero values for the classy parameters below
#targeted_rms (float) is the targeted one-point velocity variance (root squared) in Mpc/h. Required if velocity = True. The code compute_velocity_rms.py helps you to estimate this parameter on your own data
#alpha (float) is used for assigning peculiar velocities to particles. It can be obtained by fitting the relation sigma**2 = beta (delta +1)**alpha where sigma is the squared velocity dispersion in regions defined by local density contrast delta. Required if velocity = True. The code compute_alpha.py helps you to estimate alpha on your own data

Pk_tt_file   = 
targeted_rms = 3.9873
alpha        = 0.750

[OUTPUTS]
#output_dir (float) is the directory where every files related to this .ini file will be stored (predictions, simulations, estimated Pks...)
#velocity (bin) can be set to True or False if you want to simulate peculiar velocities or not
#compute_Pk_prediction (bin) and compute_2pcf_prediction (bin) to compute the prediction of the (real space only) power spectrum and two-point correlation function (both submitted to unavoidable grid and poisson filterings of the COVMOS method)
#estimate_Pk_multipoles (str,bin) uses NBodyKit in order to estimate the multipoles of the power spectrum in real space and in redshift space (using plane parallel approximation) if velocity = True. Three options : 'stopandrun' to pause the simulation process while estimating the power spectra, 'detached' if you want the estimation to be run in parallel of your simulations, or False if you don't want any Pk estimation. This parameter can be modified at any time
#save_catalogue (bin) is the option to keep or not the simulated catalogues (the user can choose to keep only the estimated power spectra)
#verbose (bin) prints the various steps and intermediate results of the codes
#debug (bin) saves several intermediate files for a debugging procedure

output_dir              = /datadec/cppm/baratta/COVMOS/covmos_public_test
velocity                = True
compute_Pk_prediction   = False
compute_2pcf_prediction = True
estimate_Pk_multipoles  = stopandrun
save_catalogue          = True
verbose                 = True
debug                   = True